{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# PyTorch Zero-to-Mastery Tutorial\n",
    "\n",
    "## About\n",
    "\n",
    "Hello everyone. My name is Meshkat. For AI enthusiasts, I developed this jupyter notebook to have an understanding of PyTorch library, how to use it, when to use it, and what should be done in order to understand all aspects of that library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 1. Installation\n",
    "\n",
    "You can install the PyTorch library with CUDA activated. In simple terms, CUDA is a layer above your NVIDIA GPU, which accelerates training time and use your VRAM (your GPU RAM) for storing your data. It has some more details that we cover later.\n",
    "\n",
    "**Note**: Use [this link](https://pytorch.org/get-started/locally/) to install PyTorch regarding your system configs and your CUDA version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:36:16.537883Z",
     "start_time": "2024-07-06T14:36:11.212573Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (2.3.1+cu118)\n",
      "Requirement already satisfied: torchvision in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (0.18.1)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.3.1%2Bcu118-cp310-cp310-win_amd64.whl (4.0 MB)\n",
      "Requirement already satisfied: jinja2 in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: filelock in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: networkx in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: fsspec in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: numpy in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (from torchvision) (2.0.0)\n",
      "Requirement already satisfied: tbb==2021.* in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.3.1+cu118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Or you can use torch on CPU by just running the below command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T13:44:34.803575Z",
     "start_time": "2024-07-06T13:44:33.535037Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: torchvision in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (0.18.1)\n",
      "Requirement already satisfied: jinja2 in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: filelock in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: sympy in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: fsspec in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: numpy in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (from torchvision) (2.0.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 2. Chek Installation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Check what version of PyTorch you're using by:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:45:17.996516Z",
     "start_time": "2024-07-06T14:45:16.961678Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.3.1+cu118\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: h:\\documents\\work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages\n",
      "Requires: filelock, fsspec, jinja2, mkl, networkx, sympy, typing-extensions\n",
      "Required-by: torchaudio, torchvision\n"
     ]
    }
   ],
   "source": [
    "!pip show torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Check whether you have CUDA or not:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:45:22.645536Z",
     "start_time": "2024-07-06T14:45:22.631213Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. PyTorch is running on GPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. PyTorch is running on GPU.\")\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch is running on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 3. Tensors\n",
    "\n",
    "Tensors are building blocks of torch. Your data will be converted into tensors to do the calculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:45:41.279893Z",
     "start_time": "2024-07-06T14:45:41.238769Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_from_list: tensor([1, 2, 3, 4]), type: <class 'torch.Tensor'>\n",
      "data type of float32: tensor([1., 2., 3.])\n",
      "random_tensor: tensor([[-0.6662, -0.4889, -1.0792],\n",
      "        [-1.1445, -0.1601, -2.1224],\n",
      "        [-0.1507,  0.6502, -1.8212]])\n",
      "zeros_tensor: tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "ones_tensor: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "eye tensor: tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"H:\\Documents\\Work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"H:\\Documents\\Work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"H:\\Documents\\Work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"H:\\Documents\\Work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"H:\\Documents\\Work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"H:\\Documents\\Work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"H:\\Documents\\Work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"H:\\Documents\\Work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"H:\\Documents\\Work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"H:\\Documents\\Work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"H:\\Documents\\Work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"H:\\Documents\\Work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"H:\\Documents\\Work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"H:\\Documents\\Work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"H:\\Documents\\Work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"H:\\Documents\\Work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"H:\\Documents\\Work\\pytorch-zero-to-mastery\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_39360\\1312163059.py\", line 5, in <module>\n",
      "    tensor_from_list = torch.tensor(sample_list)\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_39360\\1312163059.py:5: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  tensor_from_list = torch.tensor(sample_list)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Creating a tensor from a list\n",
    "sample_list = [1, 2, 3, 4]\n",
    "tensor_from_list = torch.tensor(sample_list)\n",
    "print(f'tensor_from_list: {tensor_from_list}, type: {type(tensor_from_list)}')\n",
    "\n",
    "# With specific data type\n",
    "tensor = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)\n",
    "print(f'data type of float32: {tensor}')\n",
    "\n",
    "# Creating a tensor with random values\n",
    "# for example: with size of 3*3\n",
    "random_tensor = torch.randn(3, 3)\n",
    "print(f'random_tensor: {random_tensor}')\n",
    "\n",
    "# Creating a tensor filled with zeros\n",
    "zeros_tensor = torch.zeros(3, 3)\n",
    "print(f'zeros_tensor: {zeros_tensor}')\n",
    "\n",
    "# Creating a tensor filled with ones\n",
    "ones_tensor = torch.ones(3, 3)\n",
    "print(f'ones_tensor: {ones_tensor}')\n",
    "\n",
    "# Identity matrix\n",
    "tensor = torch.eye(3)\n",
    "print(f'eye tensor: {tensor}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 3.1. Tensor Operations:\n",
    "\n",
    "You can have all the arithmetics on tensors. The operators (+, -, \\*, /) are all overrided and are equivalent to calling the torch.\\<func>(<input_1>, <input_2>)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:46:18.550099Z",
     "start_time": "2024-07-06T14:46:18.535100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add: tensor([5, 7, 9])\n",
      "sub: tensor([-3, -3, -3])\n",
      "mult: tensor([ 4, 10, 18])\n",
      "division: tensor([0.2500, 0.4000, 0.5000])\n",
      "power: tensor([1, 4, 9])\n",
      "tensor([4, 6])\n"
     ]
    }
   ],
   "source": [
    "#Example Tensors of a and b:\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "\n",
    "# Addition\n",
    "c = a + b\n",
    "print(f'add: {torch.add(a, b)}')\n",
    "\n",
    "\n",
    "# Subtraction\n",
    "c = a - b\n",
    "print(f'sub: {torch.sub(a, b)}')\n",
    "\n",
    "\n",
    "# Multiplication\n",
    "c = a * b\n",
    "print(f'mult: {torch.mul(a, b)}')\n",
    "\n",
    "\n",
    "# Division\n",
    "c = a / b\n",
    "print(f'division: {torch.div(a, b)}')\n",
    "\n",
    "# Exponentiation\n",
    "c = a ** 2\n",
    "print(f'power: {torch.pow(a, 2)}')\n",
    "\n",
    "# Tensor addition\n",
    "a = torch.tensor([1, 2])\n",
    "b = torch.tensor([3, 4])\n",
    "print(a + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 3.2. Matrix Operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:46:20.731294Z",
     "start_time": "2024-07-06T14:46:20.672729Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigvals = tensor([-0.5211+0.0000j,  1.0233+0.8075j,  1.0233-0.8075j])\n",
      "eigvecs = tensor([[-0.6197+0.0000j,  0.7467+0.0000j,  0.7467-0.0000j],\n",
      "        [-0.5336+0.0000j, -0.1745-0.5960j, -0.1745+0.5960j],\n",
      "        [ 0.5755+0.0000j,  0.2332+0.0484j,  0.2332-0.0484j]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "a = torch.randn(2, 3)\n",
    "b = torch.randn(3, 2)\n",
    "c = torch.matmul(a, b)\n",
    "\n",
    "# Element-wise multiplication\n",
    "c = a * b.T  # Transpose b to match dimensions\n",
    "\n",
    "# Matrix transpose\n",
    "c = a.t()\n",
    "\n",
    "# Matrix inverse\n",
    "a = torch.randn(3, 3)\n",
    "a_inv = torch.inverse(a)\n",
    "\n",
    "# Determinant\n",
    "det = torch.det(a)\n",
    "\n",
    "# Eigenvalues and eigenvectors\n",
    "L_complex, V_complex = torch.linalg.eig(a)\n",
    "print(f'eigvals = {L_complex}')\n",
    "print(f'eigvecs = {V_complex}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 3.3. Advanced Operation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### 3.3.1. Reshaping and Slicing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T15:12:54.381419Z",
     "start_time": "2024-07-06T15:12:54.349301Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = tensor([[ 1.6423, -0.1596, -0.4974,  0.4396],\n",
      "        [-0.7581,  1.0783,  0.8008,  1.6806],\n",
      "        [ 1.2791,  1.2964,  0.6105,  1.3347],\n",
      "        [-0.2316,  0.0418, -0.2516,  0.8599]])\n",
      "view = tensor([[ 1.6423, -0.1596, -0.4974,  0.4396, -0.7581,  1.0783,  0.8008,  1.6806],\n",
      "        [ 1.2791,  1.2964,  0.6105,  1.3347, -0.2316,  0.0418, -0.2516,  0.8599]])\n",
      "reshape = tensor([[ 1.6423, -0.1596, -0.4974,  0.4396, -0.7581,  1.0783,  0.8008,  1.6806],\n",
      "        [ 1.2791,  1.2964,  0.6105,  1.3347, -0.2316,  0.0418, -0.2516,  0.8599]])\n",
      "unsqueeze = tensor([[[ 1.6423, -0.1596, -0.4974,  0.4396],\n",
      "         [-0.7581,  1.0783,  0.8008,  1.6806],\n",
      "         [ 1.2791,  1.2964,  0.6105,  1.3347],\n",
      "         [-0.2316,  0.0418, -0.2516,  0.8599]]])\n",
      "squeeze = tensor([[ 1.6423, -0.1596, -0.4974,  0.4396],\n",
      "        [-0.7581,  1.0783,  0.8008,  1.6806],\n",
      "        [ 1.2791,  1.2964,  0.6105,  1.3347],\n",
      "        [-0.2316,  0.0418, -0.2516,  0.8599]])\n",
      "transpose = tensor([[ 1.6423, -0.7581,  1.2791, -0.2316],\n",
      "        [-0.1596,  1.0783,  1.2964,  0.0418],\n",
      "        [-0.4974,  0.8008,  0.6105, -0.2516],\n",
      "        [ 0.4396,  1.6806,  1.3347,  0.8599]])\n",
      "permute = tensor([[ 1.6423, -0.7581,  1.2791, -0.2316],\n",
      "        [-0.1596,  1.0783,  1.2964,  0.0418],\n",
      "        [-0.4974,  0.8008,  0.6105, -0.2516],\n",
      "        [ 0.4396,  1.6806,  1.3347,  0.8599]])\n",
      "tensor 'a' with first row and all columns: tensor([ 1.6423, -0.1596, -0.4974,  0.4396])\n",
      "tensor 'a' with all rows and second column: tensor([-0.1596,  1.0783,  1.2964,  0.0418])\n",
      "tensor 'a' with rows number of 0 and 1, and column number of 1 and 2: tensor([[-0.1596, -0.4974],\n",
      "        [ 1.0783,  0.8008]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(4, 4)\n",
    "print(f'a = {a}')\n",
    "\n",
    "# Reshape (or view)\n",
    "b = a.view(2, 8)\n",
    "print(f'view = {b}')\n",
    "b = a.reshape(2, 8)\n",
    "print(f'reshape = {b}')\n",
    "\n",
    "# Squeeze and unsqueeze\n",
    "b = a.unsqueeze(0)  # Add a dimension\n",
    "print(f'unsqueeze = {b}')\n",
    "c = b.squeeze(0)    # Remove a dimension\n",
    "print(f'squeeze = {c}')\n",
    "\n",
    "# Transpose and permute\n",
    "b = a.transpose(0, 1)  # Swap dimensions\n",
    "print(f'transpose = {b}')\n",
    "\n",
    "c = a.permute(1, 0)    # Permute dimensions\n",
    "print(f'permute = {c}')\n",
    "\n",
    "# Indexing and slicing\n",
    "b = a[0, :]\n",
    "print(f'tensor \\'a\\' with first row and all columns: {b}')\n",
    "c = a[:, 1]\n",
    "print(f'tensor \\'a\\' with all rows and second column: {c}')\n",
    "\n",
    "d = a[0:2, 1:3]\n",
    "print(f'tensor \\'a\\' with rows number of 0 and 1, and column number of 1 and 2: {d}') # 2 by 2 matrix\n",
    "\n",
    "a = tensor([[-1.4623, -0.7722, -1.4488,  1.1760],\n",
    "        [-0.6497,  1.7598,  1.4511, -1.8684],\n",
    "        [ 0.7739, -0.3217, -0.2484, -0.7102],\n",
    "        [ 0.5602,  0.7355,  0.1892,  0.1634]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Note in using random:\n",
    "\n",
    "If you don't want to generate different values each time when you call the `torch.randn()` or `torch.rand()`, you can set seeds so that each time you get the same random value. (useful for testing)\n",
    "\n",
    "To do so, just use the code below:\n",
    "\n",
    "```\n",
    "torch.manual_seed(42)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:57:29.943753Z",
     "start_time": "2024-07-06T14:57:29.934730Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9269,  1.4873,  0.9007, -2.1055],\n",
       "        [ 0.6784, -1.2345, -0.0431, -1.6047],\n",
       "        [-0.7521,  1.6487, -0.3925, -1.4036],\n",
       "        [-0.7279, -0.5594, -0.7688,  0.7624]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.randn(4, 4)\n",
    "# your output would be always be:\n",
    "# tensor([[ 1.9269,  1.4873,  0.9007, -2.1055],\n",
    "#         [ 0.6784, -1.2345, -0.0431, -1.6047],\n",
    "#         [-0.7521,  1.6487, -0.3925, -1.4036],\n",
    "#         [-0.7279, -0.5594, -0.7688,  0.7624]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### 3.3.2. Reductions and Aggregations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T15:03:53.458330Z",
     "start_time": "2024-07-06T15:03:53.433332Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "torch.sum: 10\n",
      "torch.mean: 2.5\n",
      "torch.std: 2.5\n",
      "min value: tensor([1, 2]), \n",
      "min index: tensor([0, 0]),\n",
      "max value: tensor([2, 4]), \n",
      "max index: tensor([1, 1])\n",
      "min_idx = 0, max_idx = 3\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "print(f'a = {a}')\n",
    "# Sum\n",
    "total = torch.sum(a)\n",
    "print(f'torch.sum: {total}')\n",
    "\n",
    "# Mean\n",
    "mean = torch.mean(a.float())\n",
    "print(f'torch.mean: {mean}')\n",
    "\n",
    "# Standard deviation\n",
    "std = torch.std(a.float())\n",
    "print(f'torch.std: {mean}')\n",
    "\n",
    "# Min and max\n",
    "min_val, min_idx = torch.min(a, dim=0)\n",
    "max_val, max_idx = torch.max(a, dim=1)\n",
    "print(f'min value: {min_val}, \\n'\n",
    "      f'min index: {min_idx},\\n'\n",
    "      f'max value: {max_val}, \\n'\n",
    "      f'max index: {max_idx}')\n",
    "\n",
    "\n",
    "# Argmin and argmax\n",
    "min_idx = torch.argmin(a)\n",
    "max_idx = torch.argmax(a)\n",
    "print(f'min_idx = {min_idx}, max_idx = {max_idx}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### 3.3.3. Comparison Operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T15:08:49.619256Z",
     "start_time": "2024-07-06T15:08:49.571642Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is 'a' greater than b: tensor([False, False,  True])\n",
      "is 'a' greater or equal than b: tensor([False,  True,  True])\n",
      "d is the boolean if a equals b or not: tensor([False,  True, False])\n",
      "c = tensor([False, False,  True])\n",
      "is any of value of 'c' equals true? : True\n",
      "are all of the values of 'c' equals true? : False\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([3, 2, 1])\n",
    "\n",
    "# Element-wise comparisons\n",
    "c = a > b\n",
    "print(f'is \\'a\\' greater than b: {c}')\n",
    "p = a >= b\n",
    "print(f'is \\'a\\' greater or equal than b: {p}')\n",
    "d = a == b\n",
    "print(f'd is the boolean if a equals b or not: {d}')\n",
    "\n",
    "# Boolean reductions\n",
    "any_true = torch.any(c)\n",
    "all_true = torch.all(c)\n",
    "print(f'c = {c}')\n",
    "print(f\"is any of value of 'c' equals true? : {any_true}\")\n",
    "print(f\"are all of the values of 'c' equals true? : {all_true}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### 3.3.4. Broadcasting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T15:15:23.810070Z",
     "start_time": "2024-07-06T15:15:23.805070Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c = tensor([[2, 4, 6],\n",
      "        [5, 7, 9]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "b = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Broadcast b to match the shape of a\n",
    "c = a + b\n",
    "print(f'c = {c}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 3.4. Random Tensor Operations\n",
    "\n",
    "check out [this note](#note-in-using-random)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T15:17:38.285129Z",
     "start_time": "2024-07-06T15:17:38.276642Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random tensor created with torch.rand: tensor([[0.9346, 0.5936, 0.8694],\n",
      "        [0.5677, 0.7411, 0.4294],\n",
      "        [0.8854, 0.5739, 0.2666]])\n",
      "random tensor created with torch.randn: tensor([[ 1.2211,  0.1511, -0.3319],\n",
      "        [-0.4785, -0.2631, -0.1786],\n",
      "        [-1.1859, -0.8860, -0.7150]])\n",
      "random integer generation: tensor([[2, 7, 6],\n",
      "        [4, 6, 5],\n",
      "        [0, 4, 0]])\n",
      "choices = tensor([2, 3, 0])\n"
     ]
    }
   ],
   "source": [
    "# Random tensors\n",
    "random_tensor = torch.rand(3, 3)  # Uniformly distributed between [0, 1)\n",
    "print(f'random tensor created with torch.rand: {random_tensor}')\n",
    "random_tensor = torch.randn(3, 3)  # Standard normal distribution\n",
    "print(f'random tensor created with torch.randn: {random_tensor}')\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Random integers\n",
    "random_int = torch.randint(low=0, high=10, size=(3, 3))\n",
    "print(f'random integer generation: {random_int}')\n",
    "\n",
    "# Random choice\n",
    "choices = torch.multinomial(torch.tensor([0.1, 0.2, 0.3, 0.4]), 3)\n",
    "print(f'choices = {choices}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 3.5. Gradient Operations (Autograd)\n",
    "\n",
    "This is step is crutial for training. More explanation will be given in the future. In simple terms and for now, when calling the `z.backward()` function, by setting the `requires_grad=True`, the output which is `z` will be saved within `x.gard` for further calculations of loss function.\n",
    "\n",
    "In other words, Autograd is PyTorchâ€™s automatic differentiation engine that powers neural network training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T15:28:15.315732Z",
     "start_time": "2024-07-06T15:28:15.297358Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor with gradient tracking\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "print(f'x = {x}')\n",
    "# Perform operations\n",
    "y = x ** 2\n",
    "print(f'y = {y}')\n",
    "z = y * 3\n",
    "print(f'z = {z}')\n",
    "\n",
    "# Compute gradients\n",
    "z.backward()\n",
    "\n",
    "print(x.grad, x)  # dz/dx = 6x => 6*2 = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 3.6. Saving and Loading Tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T15:26:00.373053Z",
     "start_time": "2024-07-06T15:26:00.351594Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4661,  0.3623,  0.3765],\n",
       "        [-0.1808,  0.3930,  0.4327],\n",
       "        [-1.3627,  1.3564,  0.6688]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save tensor to a file\n",
    "a = torch.randn(3, 3)\n",
    "torch.save(a, 'tensor.pt')\n",
    "\n",
    "# Load tensor from a file\n",
    "tensor_from_file = torch.load('tensor.pt')\n",
    "tensor_from_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 4. Neural Networks\n",
    "\n",
    "With `torch.nn` module, you can inherit from that module and define your own `__init__()` and `forward()` function to implement a neural network model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 4.1. Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T16:23:51.968745Z",
     "start_time": "2024-07-06T16:23:51.953711Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleNN()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 4.2. Training\n",
    "\n",
    "In this part, we use the MNIST dataset to train on our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.5898\n",
      "Epoch [2/10], Loss: 0.3711\n",
      "Epoch [3/10], Loss: 0.5541\n",
      "Epoch [4/10], Loss: 0.3067\n",
      "Epoch [5/10], Loss: 0.1849\n",
      "Epoch [6/10], Loss: 0.0534\n",
      "Epoch [7/10], Loss: 0.3579\n",
      "Epoch [8/10], Loss: 0.4191\n",
      "Epoch [9/10], Loss: 0.2097\n",
      "Epoch [10/10], Loss: 0.1629\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define the data transformation\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Load the dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Define the model, loss function, and optimizer\n",
    "model = SimpleNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    for images, labels in train_loader:\n",
    "        images = images.view(-1, 784)  # Flatten the images\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/10], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 4.3. Your own dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T15:41:32.592688Z",
     "start_time": "2024-07-06T15:41:32.578687Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "data = torch.randn(100, 784)\n",
    "labels = torch.randint(0, 10, (100,))\n",
    "\n",
    "dataset = CustomDataset(data, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 5. Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.21%\n"
     ]
    }
   ],
   "source": [
    "# Load the test dataset\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(-1, 784)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 6. Use GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = SimpleNN().to(device)\n",
    "images, labels = images.to(device), labels.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 6.1. Extending previous example and use GPU for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. PyTorch is running on GPU.\n",
      "Tensor is on: cpu\n",
      "Tensor moved to: cuda:0\n",
      "Model parameter is on: cpu\n",
      "Model parameter is on: cpu\n",
      "Model parameter moved to: cuda:0\n",
      "Model parameter moved to: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. PyTorch is running on GPU.\")\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch is running on CPU.\")\n",
    "\n",
    "# Create a tensor and check its device\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "print(f\"Tensor is on: {tensor.device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')\n",
    "    print(f\"Tensor moved to: {tensor.device}\")\n",
    "\n",
    "# Define a simple model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc1(x)\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleNN()\n",
    "\n",
    "# Check the device of the model parameters\n",
    "for param in model.parameters():\n",
    "    print(f\"Model parameter is on: {param.device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to('cuda')\n",
    "    for param in model.parameters():\n",
    "        print(f\"Model parameter moved to: {param.device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
